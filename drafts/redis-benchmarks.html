<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">
<head>
    <title>Redis 到底有多快[译文]</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Open Graph tags -->

            <meta property="og:type" content="article"/>
            <meta property="og:title" content="Redis 到底有多快[译文]"/>
            <meta property="og:url" content="/2014/01/redis-benchmarks/"/>
            <meta property="og:description" content="原文地址 http://redis.io/topics/benchmarks。 Redis includes the redis-benchmark utility that simulates running commands done by N clients at the same time sending M total queries (it is similar to the Apache's ab utility). Below you'll find the full output of a benchmark executed against a Linux ..."/>

    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">
    <link href="/theme/css/pygments.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>
    <!-- JavaScript plugins (requires jQuery) -->
    <script src="http://code.jquery.com/jquery.js"></script>


    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-8822123-3']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();

    </script>
</head>
<body>
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">Log4D</a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                    <li><a href="/tags/">Tags</a></li>
                    <li><a href="/links/">Links</a></li>
                    <li><a href="/about/">About</a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li><a href="/archives/"><i class="icon-th-list"></i>Archives</a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</nav>
<!-- /.navbar -->
<div class="container">
    <div class="row">
        <div class="col-lg-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/2014/01/redis-benchmarks/"
                       rel="bookmark"
                       title="Permalink to Redis 到底有多快[译文]">
                        Redis 到底有多快[译文]
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="icon-calendar"></i>2014-01-08
    </span>



<span class="label label-default">Tags</span>
	<a href="/tag/svn/">SVN</a>
        /
	<a href="/tag/git/">Git</a>
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>原文地址 <a href="http://redis.io/topics/benchmarks">http://redis.io/topics/benchmarks</a>。</p>
<p>Redis includes the <code>redis-benchmark</code> utility that simulates running commands done
by N clients at the same time sending M total queries (it is similar to the
Apache's <code>ab</code> utility). Below you'll find the full output of a benchmark executed
against a Linux box.</p>
<p>Redis 自带了一个叫 <code>redis-benchmark</code> 的工具来模拟 N 个客户端同事发出 M 个请求。
（类似于 Apache <code>ab</code> 程序）。你可以使用 <code>redis-benchmark -h</code> 来查看基准参数。</p>
<div class="highlight"><pre><span class="nx">The</span> <span class="nx">following</span> <span class="nx">options</span> <span class="nx">are</span> <span class="nx">supported</span><span class="p">:</span>

    <span class="nb">Usage</span><span class="p">:</span> <span class="nx">redis</span><span class="na">-benchmark</span> <span class="err">[</span><span class="na">-h</span> <span class="o">&lt;</span><span class="nb">host</span><span class="o">&gt;</span><span class="cp">]</span> <span class="cp">[</span><span class="na">-p</span> <span class="o">&lt;</span><span class="nb">port</span><span class="o">&gt;</span><span class="cp">]</span> <span class="cp">[</span><span class="na">-c</span> <span class="o">&lt;</span><span class="nx">clients</span><span class="o">&gt;</span><span class="cp">]</span> <span class="cp">[</span><span class="na">-n</span> <span class="o">&lt;</span><span class="nx">requests</span><span class="cp">]</span>&gt; <span class="cp">[</span><span class="na">-k</span> <span class="o">&lt;</span><span class="nb">boolean</span><span class="o">&gt;</span><span class="cp">]</span>

     -h <span class="nt">&lt;hostname&gt;</span>      Server hostname (default 127.0.0.1)
     -p <span class="nt">&lt;port&gt;</span>          Server port (default 6379)
     -s <span class="nt">&lt;socket&gt;</span>        Server socket (overrides host and port)
     -c <span class="nt">&lt;clients&gt;</span>       Number of parallel connections (default 50)
     -n <span class="nt">&lt;requests&gt;</span>      Total number of requests (default 10000)
     -d <span class="nt">&lt;size&gt;</span>          Data size of SET/GET value in bytes (default 2)
     -k <span class="nt">&lt;boolean&gt;</span>       1=keep alive 0=reconnect (default 1)
     -r <span class="nt">&lt;keyspacelen&gt;</span>   Use random keys for SET/GET/INCR, random values for SADD
      Using this option the benchmark will get/set keys
      in the form mykey_rand:000000012456 instead of constant
      keys, the <span class="nt">&lt;keyspacelen&gt;</span> argument determines the max
      number of values for the random number. For instance
      if set to 10 only rand:000000000000 - rand:000000000009
      range will be allowed.
     -P <span class="nt">&lt;numreq&gt;</span>        Pipeline <span class="nt">&lt;numreq&gt;</span> requests. Default 1 (no pipeline).
     -q                 Quiet. Just show query/sec values
     --csv              Output in CSV format
     -l                 Loop. Run the tests forever
     -t <span class="nt">&lt;tests&gt;</span>         Only run the comma separated list of tests. The test
                        names are the same as the ones produced as output.
     -I                 Idle mode. Just open N idle connections and wait.
</pre></div>


<p>You need to have a running Redis instance before launching the benchmark.
A typical example would be:</p>
<div class="highlight"><pre><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span>
</pre></div>


<p>你需要在基准测试之前启动一个 Redis 实例。一般这样启动测试：</p>
<div class="highlight"><pre><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span>
</pre></div>


<p>Using this tool is quite easy, and you can also write your own benchmark,
but as with any benchmarking activity, there are some pitfalls to avoid.</p>
<h2>Running only a subset of the tests</h2>
<p>You don't need to run all the default tests every time you execute redis-benchmark.
The simplest thing to select only a subset of tests is to use the <code>-t</code> option
like in the following example:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">t</span> <span class="n">set</span><span class="p">,</span><span class="n">lpush</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span> <span class="o">-</span><span class="n">q</span>
<span class="nl">SET:</span> <span class="mf">74239.05</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">79239.30</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p>In the above example we asked to just run test the SET and LPUSH commands,
in quite mode (see the <code>-q</code> switch).</p>
<p>It is also possible to specify the command to benchmark directly like in the
following example:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span> <span class="o">-</span><span class="n">q</span> <span class="n">script</span> <span class="n">load</span> <span class="s">&quot;redis.call(&#39;set&#39;,&#39;foo&#39;,&#39;bar&#39;)&quot;</span>
<span class="n">script</span> <span class="n">load</span> <span class="n">redis</span><span class="p">.</span><span class="n">call</span><span class="p">(</span><span class="err">&#39;</span><span class="n">set</span><span class="sc">&#39;,&#39;</span><span class="n">foo</span><span class="sc">&#39;,&#39;</span><span class="n">bar</span><span class="err">&#39;</span><span class="p">)</span><span class="o">:</span> <span class="mf">69881.20</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<h2>Selecting the size of the key space</h2>
<p>By default the benchmark runs against a single key. In Redis the difference
between such a synthetic benchmark and a real one is not huge since it is an
in memory system, however it is possible to stress cache misses and in general
to simulate a more real-world work load by using a large key space.</p>
<p>This is obtained by using the <code>-r</code> switch. For instance if I want to run
one million of SET operations, using a random key for every operation out of
100k possible keys, I'll use the following command line:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="n">redis</span><span class="o">-</span><span class="n">cli</span> <span class="n">flushall</span>
<span class="n">OK</span>

<span class="err">$</span> <span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">t</span> <span class="n">set</span> <span class="o">-</span><span class="n">r</span> <span class="mi">100000</span> <span class="o">-</span><span class="n">n</span> <span class="mi">1000000</span>
<span class="o">======</span> <span class="n">SET</span> <span class="o">======</span>
  <span class="mi">1000000</span> <span class="n">requests</span> <span class="n">completed</span> <span class="n">in</span> <span class="mf">13.86</span> <span class="n">seconds</span>
  <span class="mi">50</span> <span class="n">parallel</span> <span class="n">clients</span>
  <span class="mi">3</span> <span class="n">bytes</span> <span class="n">payload</span>
  <span class="n">keep</span> <span class="n">alive</span><span class="o">:</span> <span class="mi">1</span>

<span class="mf">99.76</span><span class="o">%</span> <span class="err">`</span><span class="o">&lt;=</span><span class="err">`</span> <span class="mi">1</span> <span class="n">milliseconds</span>
<span class="mf">99.98</span><span class="o">%</span> <span class="err">`</span><span class="o">&lt;=</span><span class="err">`</span> <span class="mi">2</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="err">`</span><span class="o">&lt;=</span><span class="err">`</span> <span class="mi">3</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="err">`</span><span class="o">&lt;=</span><span class="err">`</span> <span class="mi">3</span> <span class="n">milliseconds</span>
<span class="mf">72144.87</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>

<span class="err">$</span> <span class="n">redis</span><span class="o">-</span><span class="n">cli</span> <span class="n">dbsize</span>
<span class="p">(</span><span class="n">integer</span><span class="p">)</span> <span class="mi">99993</span>
</pre></div>


<h2>Using pipelining</h2>
<p>By default every client (the benchmark simulates 50 clients if not otherwise
specified with <code>-c</code>) sends the next command only when the reply of the previous
command is received, this means that the server will likely need a read call
in order to read each command from every client. Also RTT is payed as well.</p>
<p>Redis supports <a href="pipelining">/topics/pipelining</a>, so it is possible to send
multiple commands at once, a feature often exploited by real world applications.
Redis pipelining is able to dramatically improve the number of operations per
second a server is able do deliver.</p>
<p>This is an example of running the benchmark in a Macbook air 11" using a
pipeling of 16 commands:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">n</span> <span class="mi">1000000</span> <span class="o">-</span><span class="n">t</span> <span class="n">set</span><span class="p">,</span><span class="n">get</span> <span class="o">-</span><span class="n">P</span> <span class="mi">16</span> <span class="o">-</span><span class="n">q</span>
<span class="nl">SET:</span> <span class="mf">403063.28</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">508388.41</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p>Using pipelining resulted into a sensible amount of more commands processed.</p>
<h2>Pitfalls and misconceptions</h2>
<p>The first point is obvious: the golden rule of a useful benchmark is to
only compare apples and apples. Different versions of Redis can be compared
on the same workload for instance. Or the same version of Redis, but with
different options. If you plan to compare Redis to something else, then it is
important to evaluate the functional and technical differences, and take them
in account.</p>
<ul>
<li>Redis is a server: all commands involve network or IPC roundtrips. It is
meaningless to compare it to embedded data stores such as SQLite, Berkeley DB,
Tokyo/Kyoto Cabinet, etc ... because the cost of most operations is precisely
dominated by network/protocol management.</li>
<li>Redis commands return an acknowledgment for all usual commands. Some other
data stores do not (for instance MongoDB does not implicitly acknowledge write
operations). Comparing Redis to stores involving one-way queries is only
mildly useful.</li>
<li>Naively iterating on synchronous Redis commands does not benchmark Redis
itself, but rather measure your network (or IPC) latency. To really test Redis,
you need multiple connections (like redis-benchmark) and/or to use pipelining
to aggregate several commands and/or multiple threads or processes.</li>
<li>Redis is an in-memory data store with some optional persistency options. If
you plan to compare it to transactional servers (MySQL, PostgreSQL, etc ...),
then you should consider activating AOF and decide of a suitable fsync policy.</li>
<li>Redis is a single-threaded server. It is not designed to benefit from
multiple CPU cores. People are supposed to launch several Redis instances to
scale out on several cores if needed. It is not really fair to compare one
single Redis instance to a multi-threaded data store.</li>
</ul>
<p>A common misconception is that redis-benchmark is designed to make Redis
performances look stellar, the throughput achieved by redis-benchmark being
somewhat artificial, and not achievable by a real application. This is
actually plain wrong.</p>
<p>The redis-benchmark program is a quick and useful way to get some figures and
evaluate the performance of a Redis instance on a given hardware. However,
by default, it does not represent the maximum throughput a Redis instance can
sustain. Actually, by using pipelining and a fast client (hiredis), it is fairly
easy to write a program generating more throughput than redis-benchmark. The
default behavior of redis-benchmark is to achieve throughput by exploiting
concurrency only (i.e. it creates several connections to the server).
It does not use pipelining or any parallelism at all (one pending query per
connection at most, and no multi-threading).</p>
<p>To run a benchmark using pipelining mode (and achieve higher throughputs),
you need to explicitly use the -P option. Please note that it is still a
realistic behavior since a lot of Redis based applications actively use
pipelining to improve performance.</p>
<p>Finally, the benchmark should apply the same operations, and work in the same way
with the multiple data stores you want to compare. It is absolutely pointless to
compare the result of redis-benchmark to the result of another benchmark
program and extrapolate.</p>
<p>For instance, Redis and memcached in single-threaded mode can be compared on
GET/SET operations. Both are in-memory data stores, working mostly in the same
way at the protocol level. Provided their respective benchmark application is
aggregating queries in the same way (pipelining) and use a similar number of
connections, the comparison is actually meaningful.</p>
<p>This perfect example is illustrated by the dialog between Redis (antirez) and
memcached (dormando) developers.</p>
<p><a href="http://antirez.com/post/redis-memcached-benchmark.html">antirez 1 - On Redis, Memcached, Speed, Benchmarks and The Toilet</a></p>
<p><a href="http://dormando.livejournal.com/525147.html">dormando - Redis VS Memcached (slightly better bench)</a></p>
<p><a href="http://antirez.com/post/update-on-memcached-redis-benchmark.html">antirez 2 - An update on the Memcached/Redis benchmark</a></p>
<p>You can see that in the end, the difference between the two solutions is not
so staggering, once all technical aspects are considered. Please note both
Redis and memcached have been optimized further after these benchmarks ...</p>
<p>Finally, when very efficient servers are benchmarked (and stores like Redis
or memcached definitely fall in this category), it may be difficult to saturate
the server. Sometimes, the performance bottleneck is on client side,
and not server-side. In that case, the client (i.e. the benchmark program itself)
must be fixed, or perhaps scaled out, in order to reach the maximum throughput.</p>
<h2>Factors impacting Redis performance</h2>
<p>There are multiple factors having direct consequences on Redis performance.
We mention them here, since they can alter the result of any benchmarks.
Please note however, that a typical Redis instance running on a low end,
non tuned, box usually provides good enough performance for most applications.</p>
<ul>
<li>Network bandwidth and latency usually have a direct impact on the performance.
It is a good practice to use the ping program to quickly check the latency
between the client and server hosts is normal before launching the benchmark.
Regarding the bandwidth, it is generally useful to estimate
the throughput in Gbits/s and compare it to the theoretical bandwidth
of the network. For instance a benchmark setting 4 KB strings
in Redis at 100000 q/s, would actually consume 3.2 Gbits/s of bandwidth
and probably fit with a 10 GBits/s link, but not a 1 Gbits/s one. In many real
world scenarios, Redis throughput is limited by the network well before being
limited by the CPU. To consolidate several high-throughput Redis instances
on a single server, it worth considering putting a 10 Gbits/s NIC
or multiple 1 Gbits/s NICs with TCP/IP bonding.</li>
<li>CPU is another very important factor. Being single-threaded, Redis favors
fast CPUs with large caches and not many cores. At this game, Intel CPUs are
currently the winners. It is not uncommon to get only half the performance on
an AMD Opteron CPU compared to similar Nehalem EP/Westmere EP/Sandy bridge
Intel CPUs with Redis. When client and server run on the same box, the CPU is
the limiting factor with redis-benchmark.</li>
<li>Speed of RAM and memory bandwidth seem less critical for global performance
especially for small objects. For large objects (&gt;10 KB), it may become
noticeable though. Usually, it is not really cost effective to buy expensive
fast memory modules to optimize Redis.</li>
<li>Redis runs slower on a VM. Virtualization toll is quite high because
for many common operations, Redis does not add much overhead on top of the
required system calls and network interruptions. Prefer to run Redis on a
physical box, especially if you favor deterministic latencies. On a
state-of-the-art hypervisor (VMWare), result of redis-benchmark on a VM
through the physical network is almost divided by 2 compared to the
physical machine, with some significant CPU time spent in system and
interruptions.</li>
<li>When the server and client benchmark programs run on the same box, both
the TCP/IP loopback and unix domain sockets can be used. It depends on the
platform, but unix domain sockets can achieve around 50% more throughput than
the TCP/IP loopback (on Linux for instance). The default behavior of
redis-benchmark is to use the TCP/IP loopback.</li>
<li>The performance benefit of unix domain sockets compared to TCP/IP loopback
tends to decrease when pipelining is heavily used (i.e. long pipelines).</li>
<li>When an ethernet network is used to access Redis, aggregating commands using
pipelining is especially efficient when the size of the data is kept under
the ethernet packet size (about 1500 bytes). Actually, processing 10 bytes,
100 bytes, or 1000 bytes queries almost result in the same throughput.
See the graph below.</li>
</ul>
<p><img alt="Data size impact" src="https://github.com/dspezia/redis-doc/raw/client_command/topics/Data_size.png" /></p>
<ul>
<li>On multi CPU sockets servers, Redis performance becomes dependant on the
NUMA configuration and process location. The most visible effect is that
redis-benchmark results seem non deterministic because client and server
processes are distributed randomly on the cores. To get deterministic results,
it is required to use process placement tools (on Linux: taskset or numactl).
The most efficient combination is always to put the client and server on two
different cores of the same CPU to benefit from the L3 cache.
Here are some results of 4 KB SET benchmark for 3 server CPUs (AMD Istanbul,
Intel Nehalem EX, and Intel Westmere) with different relative placements.
Please note this benchmark is not meant to compare CPU models between themselves
(CPUs exact model and frequency are therefore not disclosed).</li>
</ul>
<p><img alt="NUMA chart" src="https://github.com/dspezia/redis-doc/raw/6374a07f93e867353e5e946c1e39a573dfc83f6c/topics/NUMA_chart.gif" /></p>
<ul>
<li>With high-end configurations, the number of client connections is also an
important factor. Being based on epoll/kqueue, Redis event loop is quite
scalable. Redis has already been benchmarked at more than 60000 connections,
and was still able to sustain 50000 q/s in these conditions. As a rule of thumb,
an instance with 30000 connections can only process half the throughput
achievable with 100 connections. Here is an example showing the throughput of
a Redis instance per number of connections:</li>
</ul>
<p><img alt="connections chart" src="https://github.com/dspezia/redis-doc/raw/system_info/topics/Connections_chart.png" /></p>
<ul>
<li>With high-end configurations, it is possible to achieve higher throughput by
tuning the NIC(s) configuration and associated interruptions. Best throughput
is achieved by setting an affinity between Rx/Tx NIC queues and CPU cores,
and activating RPS (Receive Packet Steering) support. More information in this
<a href="https://groups.google.com/forum/#!msg/redis-db/gUhc19gnYgc/BruTPCOroiMJ">thread</a>.
Jumbo frames may also provide a performance boost when large objects are used.</li>
<li>Depending on the platform, Redis can be compiled against different memory
allocators (libc malloc, jemalloc, tcmalloc), which may have different behaviors
in term of raw speed, internal and external fragmentation.
If you did not compile Redis by yourself, you can use the INFO command to check
the mem_allocator field. Please note most benchmarks do not run long enough to
generate significant external fragmentation (contrary to production Redis
instances).</li>
</ul>
<h2>Other things to consider</h2>
<p>One important goal of any benchmark is to get reproducible results, so they
can be compared to the results of other tests.</p>
<ul>
<li>A good practice is to try to run tests on isolated hardware as far as possible.
If it is not possible, then the system must be monitored to check the benchmark
is not impacted by some external activity.</li>
<li>Some configurations (desktops and laptops for sure, some servers as well)
have a variable CPU core frequency mechanism. The policy controlling this
mechanism can be set at the OS level. Some CPU models are more aggressive than
others at adapting the frequency of the CPU cores to the workload. To get
reproducible results, it is better to set the highest possible fixed frequency
for all the CPU cores involved in the benchmark.</li>
<li>An important point is to size the system accordingly to the benchmark.
The system must have enough RAM and must not swap. On Linux, do not forget
to set the overcommit_memory parameter correctly. Please note 32 and 64 bits
Redis instances have not the same memory footprint.</li>
<li>If you plan to use RDB or AOF for your benchmark, please check there is no other
I/O activity in the system. Avoid putting RDB or AOF files on NAS or NFS shares,
or on any other devices impacting your network bandwidth and/or latency
(for instance, EBS on Amazon EC2).</li>
<li>Set Redis logging level (loglevel parameter) to warning or notice. Avoid putting
the generated log file on a remote filesystem.</li>
<li>Avoid using monitoring tools which can alter the result of the benchmark. For
instance using INFO at regular interval to gather statistics is probably fine,
but MONITOR will impact the measured performance significantly.</li>
</ul>
<h1>Benchmark results on different virtualized and bare metal servers.</h1>
<ul>
<li>The test was done with 50 simultaneous clients performing 2 million requests.</li>
<li>Redis 2.6.14 is used for all the tests.</li>
<li>Test executed using the loopback interface.</li>
<li>Test executed using a key space of 1 million keys.</li>
<li>Test executed with and without pipelining (16 commands pipeline).</li>
</ul>
<p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (with pipelining)</strong></p>
<div class="highlight"><pre><span class="err">$</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">r</span> <span class="mi">1000000</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2000000</span> <span class="o">-</span><span class="n">t</span> <span class="n">get</span><span class="p">,</span><span class="n">set</span><span class="p">,</span><span class="n">lpush</span><span class="p">,</span><span class="n">lpop</span> <span class="o">-</span><span class="n">P</span> <span class="mi">16</span> <span class="o">-</span><span class="n">q</span>
<span class="nl">SET:</span> <span class="mf">552028.75</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">707463.75</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">767459.75</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">770119.38</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (without pipelining)</strong></p>
<div class="highlight"><pre><span class="err">$</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">r</span> <span class="mi">1000000</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2000000</span> <span class="o">-</span><span class="n">t</span> <span class="n">get</span><span class="p">,</span><span class="n">set</span><span class="p">,</span><span class="n">lpush</span><span class="p">,</span><span class="n">lpop</span> <span class="o">-</span><span class="n">q</span>
<span class="nl">SET:</span> <span class="mf">122556.53</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">123601.76</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">136752.14</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">132424.03</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p><strong>Linode 2048 instance (with pipelining)</strong></p>
<div class="highlight"><pre><span class="err">$</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">r</span> <span class="mi">1000000</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2000000</span> <span class="o">-</span><span class="n">t</span> <span class="n">get</span><span class="p">,</span><span class="n">set</span><span class="p">,</span><span class="n">lpush</span><span class="p">,</span><span class="n">lpop</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">P</span> <span class="mi">16</span>
<span class="nl">SET:</span> <span class="mf">195503.42</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">250187.64</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">230547.55</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">250815.16</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p><strong>Linode 2048 instance (without pipelining)</strong></p>
<div class="highlight"><pre><span class="err">$</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">r</span> <span class="mi">1000000</span> <span class="o">-</span><span class="n">n</span> <span class="mi">2000000</span> <span class="o">-</span><span class="n">t</span> <span class="n">get</span><span class="p">,</span><span class="n">set</span><span class="p">,</span><span class="n">lpush</span><span class="p">,</span><span class="n">lpop</span> <span class="o">-</span><span class="n">q</span>
<span class="nl">SET:</span> <span class="mf">35001.75</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">37481.26</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">36968.58</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">35186.49</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<h2>More detailed tests without pipelining</h2>
<div class="highlight"><pre><span class="err">$</span> <span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span>

<span class="o">======</span> <span class="n">SET</span> <span class="o">======</span>
  <span class="mi">100007</span> <span class="n">requests</span> <span class="n">completed</span> <span class="n">in</span> <span class="mf">0.88</span> <span class="n">seconds</span>
  <span class="mi">50</span> <span class="n">parallel</span> <span class="n">clients</span>
  <span class="mi">3</span> <span class="n">bytes</span> <span class="n">payload</span>
  <span class="n">keep</span> <span class="n">alive</span><span class="o">:</span> <span class="mi">1</span>

<span class="mf">58.50</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="n">milliseconds</span>
<span class="mf">99.17</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="n">milliseconds</span>
<span class="mf">99.58</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="n">milliseconds</span>
<span class="mf">99.85</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">3</span> <span class="n">milliseconds</span>
<span class="mf">99.90</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">6</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">9</span> <span class="n">milliseconds</span>
<span class="mf">114293.71</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>

<span class="o">======</span> <span class="n">GET</span> <span class="o">======</span>
  <span class="mi">100000</span> <span class="n">requests</span> <span class="n">completed</span> <span class="n">in</span> <span class="mf">1.23</span> <span class="n">seconds</span>
  <span class="mi">50</span> <span class="n">parallel</span> <span class="n">clients</span>
  <span class="mi">3</span> <span class="n">bytes</span> <span class="n">payload</span>
  <span class="n">keep</span> <span class="n">alive</span><span class="o">:</span> <span class="mi">1</span>

<span class="mf">43.12</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="n">milliseconds</span>
<span class="mf">96.82</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="n">milliseconds</span>
<span class="mf">98.62</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">3</span> <span class="n">milliseconds</span>
<span class="mf">81234.77</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>

<span class="o">======</span> <span class="n">INCR</span> <span class="o">======</span>
  <span class="mi">100018</span> <span class="n">requests</span> <span class="n">completed</span> <span class="n">in</span> <span class="mf">1.46</span> <span class="n">seconds</span>
  <span class="mi">50</span> <span class="n">parallel</span> <span class="n">clients</span>
  <span class="mi">3</span> <span class="n">bytes</span> <span class="n">payload</span>
  <span class="n">keep</span> <span class="n">alive</span><span class="o">:</span> <span class="mi">1</span>

<span class="mf">32.32</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="n">milliseconds</span>
<span class="mf">96.67</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="n">milliseconds</span>
<span class="mf">99.14</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="n">milliseconds</span>
<span class="mf">99.83</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">3</span> <span class="n">milliseconds</span>
<span class="mf">99.88</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">4</span> <span class="n">milliseconds</span>
<span class="mf">99.89</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">5</span> <span class="n">milliseconds</span>
<span class="mf">99.96</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">9</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">18</span> <span class="n">milliseconds</span>
<span class="mf">68458.59</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>

<span class="o">======</span> <span class="n">LPUSH</span> <span class="o">======</span>
  <span class="mi">100004</span> <span class="n">requests</span> <span class="n">completed</span> <span class="n">in</span> <span class="mf">1.14</span> <span class="n">seconds</span>
  <span class="mi">50</span> <span class="n">parallel</span> <span class="n">clients</span>
  <span class="mi">3</span> <span class="n">bytes</span> <span class="n">payload</span>
  <span class="n">keep</span> <span class="n">alive</span><span class="o">:</span> <span class="mi">1</span>

<span class="mf">62.27</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="n">milliseconds</span>
<span class="mf">99.74</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="n">milliseconds</span>
<span class="mf">99.85</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="n">milliseconds</span>
<span class="mf">99.86</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">3</span> <span class="n">milliseconds</span>
<span class="mf">99.89</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">5</span> <span class="n">milliseconds</span>
<span class="mf">99.93</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">7</span> <span class="n">milliseconds</span>
<span class="mf">99.96</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">9</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">22</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">208</span> <span class="n">milliseconds</span>
<span class="mf">88109.25</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>

<span class="o">======</span> <span class="n">LPOP</span> <span class="o">======</span>
  <span class="mi">100001</span> <span class="n">requests</span> <span class="n">completed</span> <span class="n">in</span> <span class="mf">1.39</span> <span class="n">seconds</span>
  <span class="mi">50</span> <span class="n">parallel</span> <span class="n">clients</span>
  <span class="mi">3</span> <span class="n">bytes</span> <span class="n">payload</span>
  <span class="n">keep</span> <span class="n">alive</span><span class="o">:</span> <span class="mi">1</span>

<span class="mf">54.83</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="n">milliseconds</span>
<span class="mf">97.34</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="n">milliseconds</span>
<span class="mf">99.95</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="n">milliseconds</span>
<span class="mf">99.96</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">3</span> <span class="n">milliseconds</span>
<span class="mf">99.96</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">4</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">9</span> <span class="n">milliseconds</span>
<span class="mf">100.00</span><span class="o">%</span> <span class="o">&lt;=</span> <span class="mi">208</span> <span class="n">milliseconds</span>
<span class="mf">71994.96</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p>Notes: changing the payload from 256 to 1024 or 4096 bytes does not change the
numbers significantly (but reply packets are glued together up to 1024 bytes so
GETs may be slower with big payloads). The same for the number of clients, from
50 to 256 clients I got the same numbers. With only 10 clients it starts to get
a bit slower.</p>
<p>You can expect different results from different boxes. For example a low
profile box like <em>Intel core duo T5500 clocked at 1.66 GHz running Linux 2.6</em>
will output the following:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span>
<span class="nl">SET:</span> <span class="mf">53684.38</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">45497.73</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">INCR:</span> <span class="mf">39370.47</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">34803.41</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">37367.20</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p>Another one using a 64 bit box, a Xeon L5420 clocked at 2.5 GHz:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span>
<span class="nl">PING:</span> <span class="mf">111731.84</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">SET:</span> <span class="mf">108114.59</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">98717.67</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">INCR:</span> <span class="mf">95241.91</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">104712.05</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">93722.59</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<h1>Example of benchmark results with optimized high-end server hardware</h1>
<ul>
<li>Redis version <strong>2.4.2</strong></li>
<li>Default number of connections, payload size = 256</li>
<li>The Linux box is running <em>SLES10 SP3 2.6.16.60-0.54.5-smp</em>, CPU is 2 x <em>Intel X5670 @ 2.93 GHz</em>.</li>
<li>Text executed while running redis server and benchmark client on the same CPU, but different cores.</li>
</ul>
<p>Using a unix domain socket:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="n">numactl</span> <span class="o">-</span><span class="n">C</span> <span class="mi">6</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span> <span class="o">-</span><span class="n">s</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">redis</span><span class="p">.</span><span class="n">sock</span> <span class="o">-</span><span class="n">d</span> <span class="mi">256</span>
<span class="n">PING</span> <span class="p">(</span><span class="kr">inline</span><span class="p">)</span><span class="o">:</span> <span class="mf">200803.22</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">PING:</span> <span class="mf">200803.22</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">MSET</span> <span class="p">(</span><span class="mi">10</span> <span class="n">keys</span><span class="p">)</span><span class="o">:</span> <span class="mf">78064.01</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">SET:</span> <span class="mf">198412.69</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">198019.80</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">INCR:</span> <span class="mf">200400.80</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">200000.00</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">198019.80</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">SADD:</span> <span class="mf">203665.98</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">SPOP:</span> <span class="mf">200803.22</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LPUSH</span> <span class="p">(</span><span class="n">again</span><span class="p">,</span> <span class="n">in</span> <span class="n">order</span> <span class="n">to</span> <span class="n">bench</span> <span class="n">LRANGE</span><span class="p">)</span><span class="o">:</span> <span class="mf">200000.00</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">100</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">42123.00</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">300</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">15015.02</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">450</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">10159.50</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">600</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">7548.31</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>


<p>Using the TCP loopback:</p>
<div class="highlight"><pre><span class="err">$</span> <span class="n">numactl</span> <span class="o">-</span><span class="n">C</span> <span class="mi">6</span> <span class="p">.</span><span class="o">/</span><span class="n">redis</span><span class="o">-</span><span class="n">benchmark</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">n</span> <span class="mi">100000</span> <span class="o">-</span><span class="n">d</span> <span class="mi">256</span>
<span class="n">PING</span> <span class="p">(</span><span class="kr">inline</span><span class="p">)</span><span class="o">:</span> <span class="mf">145137.88</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">PING:</span> <span class="mf">144717.80</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">MSET</span> <span class="p">(</span><span class="mi">10</span> <span class="n">keys</span><span class="p">)</span><span class="o">:</span> <span class="mf">65487.89</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">SET:</span> <span class="mf">142653.36</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">GET:</span> <span class="mf">142450.14</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">INCR:</span> <span class="mf">143061.52</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPUSH:</span> <span class="mf">144092.22</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">LPOP:</span> <span class="mf">142247.52</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">SADD:</span> <span class="mf">144717.80</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="nl">SPOP:</span> <span class="mf">143678.17</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LPUSH</span> <span class="p">(</span><span class="n">again</span><span class="p">,</span> <span class="n">in</span> <span class="n">order</span> <span class="n">to</span> <span class="n">bench</span> <span class="n">LRANGE</span><span class="p">)</span><span class="o">:</span> <span class="mf">143061.52</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">100</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">29577.05</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">300</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">10431.88</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">450</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">7010.66</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
<span class="n">LRANGE</span> <span class="p">(</span><span class="n">first</span> <span class="mi">600</span> <span class="n">elements</span><span class="p">)</span><span class="o">:</span> <span class="mf">5296.61</span> <span class="n">requests</span> <span class="n">per</span> <span class="n">second</span>
</pre></div>
            </div>
            <!-- /.entry-content -->
    <hr />
    <section class="comments" id="comments">
        <h2>Comments</h2>
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'log4d'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
        </script>
		<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    

    </section>
        </article>
    </section>

        </div>
        <div class="col-lg-3 well well-sm" id="sidebar">
<aside>
    <section>
        <ul class="list-group list-group-flush">
                <li class="list-group-item"><h4><i class="icon-home icon-large"></i>Social</h4></li>
                    <li class="list-group-item"><a href="http://twitter.com/alswl"><i
                            class="icon-twitter-sign icon-large"></i>twitter
                    </a></li>
                    <li class="list-group-item"><a href="https://github.com/alswl"><i
                            class="icon-github-sign icon-large"></i>github
                    </a></li>
                    <li class="list-group-item"><a href="http://weibo.com/alswlx"><i
                            class="icon-weibo-sign icon-large"></i>weibo
                    </a></li>


                <li class="list-group-item"><h4><i class="icon-home icon-large"></i>Categories</h4></li>
                    <li class="list-group-item">
                        <a href="/category/c/">
                            <i class="icon-folder-open icon-large"></i>C
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/cheng-xu-ren-sheng/">
                            <i class="icon-folder-open icon-large"></i>程序人生
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/delphibian-cheng/">
                            <i class="icon-folder-open icon-large"></i>Delphi编程
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/dotnet/">
                            <i class="icon-folder-open icon-large"></i>dotNet
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/flashbian-cheng/">
                            <i class="icon-folder-open icon-large"></i>Flash编程
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/gan-wu/">
                            <i class="icon-folder-open icon-large"></i>感悟
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/gong-yu-shan-qi-shi-bi-xian-li-qi-qi/">
                            <i class="icon-folder-open icon-large"></i>工欲善其事必先利其器
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/guan-zhu-hu-lian-wang/">
                            <i class="icon-folder-open icon-large"></i>关注互联网
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/javabian-cheng-he-javaqi-ye-ying-yong/">
                            <i class="icon-folder-open icon-large"></i>Java编程和Java企业应用
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/ji-zhu-da-ren/">
                            <i class="icon-folder-open icon-large"></i>技术达人
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/jian-zhan/">
                            <i class="icon-folder-open icon-large"></i>建站
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/jian-zhan-xin-de/">
                            <i class="icon-folder-open icon-large"></i>建站心得
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/linuxer/">
                            <i class="icon-folder-open icon-large"></i>Linuxer
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/mei-shi-peng-ren/">
                            <i class="icon-folder-open icon-large"></i>美食|烹饪
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/microsoft-net/">
                            <i class="icon-folder-open icon-large"></i>Microsoft .Net
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/net-zong-he-ji-zhu/">
                            <i class="icon-folder-open icon-large"></i>.Net, 综合技术
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/phpbian-cheng/">
                            <i class="icon-folder-open icon-large"></i>PHP编程
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/pythonbian-cheng/">
                            <i class="icon-folder-open icon-large"></i>Python编程
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/qian-duan/">
                            <i class="icon-folder-open icon-large"></i>前端
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/qing-chun-de-cai-hong/">
                            <i class="icon-folder-open icon-large"></i>青春的彩虹
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/ri-ji/">
                            <i class="icon-folder-open icon-large"></i>日记
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/ruan-jian-kai-fa-he-xiang-mu-guan-li/">
                            <i class="icon-folder-open icon-large"></i>软件开发和项目管理
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/ruby-bian-cheng/">
                            <i class="icon-folder-open icon-large"></i>Ruby 编程
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/shi-jue-she-ji/">
                            <i class="icon-folder-open icon-large"></i>视觉设计
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/sui-sui-nian/">
                            <i class="icon-folder-open icon-large"></i>碎碎念
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/webqian-duan/">
                            <i class="icon-folder-open icon-large"></i>Web前端
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/wu-hua-ba-men/">
                            <i class="icon-folder-open icon-large"></i>五花八门
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/xue-hai-wu-ya/">
                            <i class="icon-folder-open icon-large"></i>学海无涯
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/yi-dong-shou-chi/">
                            <i class="icon-folder-open icon-large"></i>移动手持
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/yu-le/">
                            <i class="icon-folder-open icon-large"></i>娱乐
                        </a>
                    </li>
                    <li class="list-group-item">
                        <a href="/category/zong-he-ji-zhu/">
                            <i class="icon-folder-open icon-large"></i>综合技术
                        </a>
                    </li>

        </ul>
    </section>
</aside>        </div>
    </div>
</div>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'log4d'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
</body>
</html>